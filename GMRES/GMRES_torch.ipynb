{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9230d73",
   "metadata": {},
   "source": [
    "# LEFT PRECONDITIONED GMRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12795192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import linalg as lg\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49c7a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the numpy array\n",
    "# A = np.array([[1, 1, 4, 9], [3, 4, 6, 9], [4, 1, 1, 3], [3, 2, 1, 1]])\n",
    "\n",
    "# # Convert to COO format\n",
    "# coo = torch.sparse_coo_tensor(indices=torch.tensor(np.nonzero(A)).long(), values=torch.tensor(A[np.nonzero(A)]).float(), size=A.shape)\n",
    "\n",
    "# # Convert COO to CSR format\n",
    "# csr = coo.to_sparse_csr()\n",
    "\n",
    "# print(coo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bf065ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fb_solve(L, U, r):\n",
    "    y = L.solve_triangular(upper=False, unit=False, b=r)\n",
    "    z = U.solve_triangular(upper=True, unit=False, b=y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44ca9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It works fine, I have tested it comparing it with the results of arnoldi_one_iter.ipynb\n",
    "\n",
    "def arnoldi_one_iter(prec, A, V, k, tol=1e-12):\n",
    "    \"\"\"\n",
    "    Computes the new vectors of the Arnoldi iteration for both V_{k+1} and H_{k + 1, k}\n",
    "\n",
    "    Input parameters:\n",
    "    -----------------\n",
    "    A: array_like\n",
    "         An (n x n) array.\n",
    "          \n",
    "    V: array_like\n",
    "        An (n x (k + 1)) array. The current Krylov orthonormal basis.\n",
    "      \n",
    "    k: int\n",
    "        One less than the step we are obtaining in the Arnoldi's algorithm to increase\n",
    "        the dimension of the Krylov subspace. Must be >= 0.\n",
    "    \n",
    "    precondition: PreconditionEnum or None\n",
    "        An enumeration representing the preconditioning method to be applied.\n",
    "        \n",
    "    M: scipy.sparse matrix or None\n",
    "        The preconditioning matrix if applicable, otherwise None.    \n",
    "      \n",
    "    epsilon : float, optional\n",
    "        Tolerance for convergence.\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "      h_k: \n",
    "          \n",
    "      v_new:\n",
    "          \n",
    "    \"\"\"\n",
    "    # Note that to obtain the first column of H ((k + 1) x k) we need 2 vectors in V. Later in the GMRES algorithm\n",
    "    # we will use the notation H[: k + 2, : k + 1] as k starts at 0 and we select the first two rows and first column.\n",
    "    \n",
    "    # Here h_k respresents the column k + 1 in H. (k starts at 0)\n",
    "    \n",
    "    # Inialize k + 2 nonzero elements of H along column k. (k starts at 0)\n",
    "    h_k = torch.zeros((k + 2, ))\n",
    "\n",
    "    v_new = prec(A@V[:, k])\n",
    "    \n",
    "    # Calculate first k elements of the kth Hessenberg column\n",
    "    for j in range(k + 1): # Here k is from 0 to k \n",
    "        h_k[j] = torch.dot(v_new, V[:, j])\n",
    "        v_new = v_new - h_k[j] * V[:, j]\n",
    "    \n",
    "    # Add the k+1 element\n",
    "    h_k[k + 1] = torch.norm(v_new, p = 2)\n",
    "\n",
    "    if h_k[k + 1] <= tol:\n",
    "        # None for v to check in gmres (early termination with EXACT SOLUTION)\n",
    "        return h_k, None\n",
    "    \n",
    "    else:\n",
    "        # Find the new orthogonal vector in the basis of the Krylov subspace\n",
    "        v_new = v_new / h_k[k + 1]\n",
    "\n",
    "    return h_k, v_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1183fe6e",
   "metadata": {},
   "source": [
    "Verifying the algorithm works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "091849b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 4\n",
    "# A = torch.tensor([[1, 1, 4, 9], [3, 4, 6, 9], [4, 1, 1, 3], [3, 2, 1, 1]]).float()\n",
    "# b = torch.tensor([3, 2, 2, -3]).float()\n",
    "# x0 = torch.zeros_like(b).float()\n",
    "# r0 = b - A@x0\n",
    "# r0 = r0\n",
    "# # Apply initial preconditioning to the residual\n",
    "# r0 = prec(r0)\n",
    "# p0 = torch.norm(r0, p=2)\n",
    "\n",
    "\n",
    "# V = torch.zeros((n, 1))\n",
    "# V[:, 0] = r0 / p0\n",
    "# V = torch.cat((V, torch.zeros((n, 1))), axis=1)\n",
    "\n",
    "# H = torch.zeros((n + 1, 1))\n",
    "# H = torch.cat((H, torch.zeros((n + 1, 1))), axis=1)\n",
    "# k = 0\n",
    "\n",
    "# H[:(k + 2), k], v_new  = arnoldi_one_iter(prec, A, V, k)\n",
    "# V[:, k + 1] = v_new\n",
    "# V, H\n",
    "# Q, R = lg.qr(H[:k + 2, :k + 1], mode = 'complete') # this does not support csr torch format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0ce79e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_substitution(A, b):\n",
    "    \"\"\"\n",
    "    Solve a linear system using back substitution.\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "        A: torch.Tensor\n",
    "            Coefficient matrix (must be upper triangular).\n",
    "        \n",
    "        b: torch.Tensor\n",
    "            Column vector of constants.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        torch.Tensor: Solution vector.\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the matrix A is not square or if its dimensions are incompatible with the vector b.\n",
    "    \"\"\"\n",
    "    \n",
    "    n = b.size(0)\n",
    "    \n",
    "    # Check if A is a square matrix\n",
    "    if A.size(0) != n or A.size(1) != n:\n",
    "        raise ValueError(\"Matrix A must be square.\")\n",
    "    \n",
    "    # Check if dimensions of A and b are compatible\n",
    "    if A.size(0) != b.size(0):\n",
    "        raise ValueError(\"Dimensions of A and b are incompatible.\")\n",
    "    \n",
    "    x = torch.zeros(n, dtype=b.dtype)\n",
    "    \n",
    "    for i in range(n - 1, -1, -1):\n",
    "        x[i] = (b[i] - torch.sum(A[i, i+1:] * x[i+1:])) / A[i, i]\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c48a7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precon_GMRES_restarted(prec, A, b, x0 = None, k_max = None, restart = None, epsilon = 1e-12):\n",
    "    \"\"\"\n",
    "    Generalized Minimal RESidual method for solving linear systems. With both restart and left preconditioning options.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    prec: preconditioner function\n",
    "    \n",
    "    A : torch.Tensor\n",
    "        Coefficient matrix of the linear system.\n",
    "        \n",
    "    b : torch.Tensor\n",
    "        Right-hand side vector of the linear system.\n",
    "        \n",
    "    x0 : torch.Tensor\n",
    "        Initial guess for the solution.\n",
    "        \n",
    "    k_max : int, optional\n",
    "        Maximum number of iterations. Defaults to None, which sets it to the dimension of A.\n",
    "        \n",
    "    restart : int, optional\n",
    "        Number of iterations before restart. If None, the method will not restart.\n",
    "    \n",
    "    epsilon : float, optional\n",
    "        Tolerance for convergence. Defaults to 1e-12.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    xk : torch.Tensor\n",
    "        Approximate solution to the linear system.\n",
    "    \n",
    "    error_list : list\n",
    "        List containing the error at each iteration.\n",
    "    \n",
    "    total_k : int\n",
    "        Total number of iterations performed.\n",
    "        \n",
    "    total_precondition_time : float\n",
    "        Total time spent on preconditioning.\n",
    "    \"\"\"\n",
    "    \n",
    "    x0 = x0 if x0 is not None else torch.zeros_like(b)\n",
    "    \n",
    "    n = A.shape[0]\n",
    "    \n",
    "    if k_max is None or k_max > n:\n",
    "        k_max = n\n",
    "    \n",
    "    r0 = b - A@x0\n",
    "    r0 = r0.float()\n",
    "    \n",
    "    # Apply initial preconditioning to the residual\n",
    "    r0 = prec(r0)\n",
    "\n",
    "    p0 = torch.norm(r0)\n",
    "    beta = p0.clone()\n",
    "    pk = p0.clone()\n",
    "    k = 0\n",
    "    total_k = 0\n",
    "    \n",
    "    # Save list of errors at each iteration\n",
    "    error_list = [pk]\n",
    "    \n",
    "    # Initialize the V basis of the Krylov subspace (concatenate as iteration continues). May terminate early.\n",
    "    V = torch.zeros((n, 1))\n",
    "    V[:, 0] = r0 / beta\n",
    "    \n",
    "    # Hessenberg matrix\n",
    "    H = torch.zeros((n + 1, 1))        \n",
    "    \n",
    "    while pk > epsilon * p0 and total_k < k_max: \n",
    "\n",
    "        # Arnoldi iteration\n",
    "        V = torch.cat((V, torch.zeros((n, 1))), dim=1)\n",
    "        H = torch.cat((H, torch.zeros((n + 1, 1))), dim=1)\n",
    "        \n",
    "        \n",
    "        # Minv_A will be A if precondition is None\n",
    "        H[:k + 2, k], v_new = arnoldi_one_iter(prec, A, V, k)\n",
    "\n",
    "        if v_new is None:\n",
    "            print(\"ENCOUNTER EXACT SOLUTION\")\n",
    "            # Append 0 for plots...\n",
    "            error_list.append(0)\n",
    "        \n",
    "        else:\n",
    "            V[:, k + 1] = v_new\n",
    "        \n",
    "        Q, R = lg.qr(H[:k + 2, :k + 1], mode = 'complete') # this does not support csr torch format\n",
    "        \n",
    "        pk = abs(beta * Q[0, k])  # Compute norm of residual vector\n",
    "        error_list.append(pk)  # Add new error at current iteration       \n",
    "        \n",
    "        yk = back_substitution(R[:-1, :], beta * Q[0][:-1])\n",
    "        # yk = torch.triangular_solve(beta * Q[0][:-1], R[:-1, :], upper = True)\n",
    "        xk = x0 + V[:, :k + 1]@yk  # Compute the new approximation x0 + V_{k}y\n",
    "\n",
    "        k += 1\n",
    "        total_k += 1\n",
    "        \n",
    "        if restart is not None and k == restart:\n",
    "            x0 = xk\n",
    "            r0 = b - A@x0\n",
    "            \n",
    "            r0 = prec(r0)\n",
    "            \n",
    "            p0 = torch.norm(r0)\n",
    "            beta = p0\n",
    "            pk = p0\n",
    "            k = 0\n",
    "            \n",
    "            V = torch.zeros((n, 1))\n",
    "            V[:, 0] = r0 / beta\n",
    "            H = torch.zeros((n + 1, 1))\n",
    "  \n",
    "    return xk, error_list, total_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "786b0b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.9630, -9.4445, 10.7037, -3.7037])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = \"baseline\"\n",
    "\n",
    "time_function = lambda: time.perf_counter()\n",
    "\n",
    "# Define the numpy array\n",
    "A = torch.tensor([[1, 1, 4, 9], [3, 4, 6, 9], [4, 1, 1, 3], [3, 2, 1, 1]]).float()\n",
    "b = torch.tensor([3, 2, 2, -3]).float()\n",
    "\n",
    "# Convert to COO format\n",
    "# coo = torch.sparse_coo_tensor(indices=torch.tensor(np.nonzero(A)).long(), values=torch.tensor(A[np.nonzero(A)]).float(), size=A.shape)\n",
    "\n",
    "# Start timing\n",
    "start = time_function()\n",
    "            \n",
    "if method == \"jacobi\":\n",
    "    p_start = time_function()\n",
    "    \n",
    "    data = 1 / torch.sqrt(torch.Tensor(A.diagonal()))\n",
    "    indices = torch.vstack((torch.arange(A.shape[0]), torch.arange(A.shape[0])))\n",
    "    M = torch.sparse_coo_tensor(indices, data, size = A.shape)\n",
    "    \n",
    "    M = M.to_sparse_csr() # optimized format for matrix multiplication\n",
    "                \n",
    "    # construct preconditioner function\n",
    "    prec = lambda x: M@x\n",
    "    \n",
    "    p_stop = time_function()\n",
    "            \n",
    "elif method == \"baseline\":\n",
    "    \n",
    "    p_start, p_stop = 0, 0\n",
    "\n",
    "    prec = lambda x: x\n",
    "            \n",
    "else:\n",
    "    raise NotImplementedError(f\"Preconditioner {method} not implemented!\")\n",
    "                \n",
    "stop = time_function()\n",
    "p_time = (p_stop - p_start)\n",
    "overhead = (stop - start) - (p_time)\n",
    "            \n",
    "x, _, _ = precon_GMRES_restarted(prec, A, b)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c32e9b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.96296296 -9.44444444 10.7037037  -3.7037037 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 2.9630, -9.4445, 10.7037, -3.7037])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse.linalg as spla\n",
    "\n",
    "A = np.array([[1, 1, 4, 9], [3, 4, 6, 9], [4, 1, 1, 3], [3, 2, 1, 1]])\n",
    "b = np.array([3, 2, 2, -3])\n",
    "x0 = np.array([0, 0, 0, 0])\n",
    "\n",
    "print(spla.gmres(A, b, x0, restart = None)[0])\n",
    "\n",
    "A = torch.tensor([[1, 1, 4, 9], [3, 4, 6, 9], [4, 1, 1, 3], [3, 2, 1, 1]]).float()\n",
    "b = torch.tensor([3, 2, 2, -3]).float()\n",
    "x0 = torch.tensor([0, 0, 0, 0]).float()\n",
    "\n",
    "precon_GMRES_restarted(prec, A, b, x0, 4)[0] # Converges in n = 4 iterations! God"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64dc9eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def discretise_poisson(N):\n",
    "    \"\"\"Generate the matrix and rhs associated with the discrete Poisson operator.\"\"\"\n",
    "    \n",
    "    nelements = 5 * N**2 - 16 * N + 16\n",
    "    \n",
    "    row_ind = np.empty(nelements, dtype=np.float64)\n",
    "    col_ind = np.empty(nelements, dtype=np.float64)\n",
    "    data = np.empty(nelements, dtype=np.float64)\n",
    "    \n",
    "    f = np.empty(N * N, dtype=np.float64)\n",
    "    \n",
    "    count = 0\n",
    "    for j in range(N):\n",
    "        for i in range(N):\n",
    "            if i == 0 or i == N - 1 or j == 0 or j == N - 1:\n",
    "                row_ind[count] = col_ind[count] = j * N + i\n",
    "                data[count] =  1\n",
    "                f[j * N + i] = 0\n",
    "                count += 1\n",
    "                \n",
    "            else:\n",
    "                row_ind[count : count + 5] = j * N + i\n",
    "                col_ind[count] = j * N + i\n",
    "                col_ind[count + 1] = j * N + i + 1\n",
    "                col_ind[count + 2] = j * N + i - 1\n",
    "                col_ind[count + 3] = (j + 1) * N + i\n",
    "                col_ind[count + 4] = (j - 1) * N + i\n",
    "                                \n",
    "                data[count] = 4 * (N - 1)**2\n",
    "                data[count + 1 : count + 5] = - (N - 1)**2\n",
    "                f[j * N + i] = 1\n",
    "                \n",
    "                count += 5\n",
    "                                                \n",
    "    return coo_matrix((data, (row_ind, col_ind)), shape=(N**2, N**2)), f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41f51721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Extract row indices, column indices, and data\n",
    "\n",
    "N = 40\n",
    "\n",
    "A, b = discretise_poisson(N)\n",
    "\n",
    "row_indices = torch.tensor(A.row, dtype=torch.long)\n",
    "col_indices = torch.tensor(A.col, dtype=torch.long)\n",
    "values = torch.tensor(A.data, dtype=torch.float)\n",
    "\n",
    "# Step 2: Create COO tensor in PyTorch\n",
    "A = torch.sparse_coo_tensor(torch.stack((row_indices, col_indices)), values, A.shape)\n",
    "\n",
    "# Step 3: Convert COO tensor to dense PyTorch tensor\n",
    "dense_tensor = A.to_dense().float()\n",
    "b = torch.tensor(b).float()\n",
    "x0 = torch.zeros_like(b).float()\n",
    "type(A), type(b), type(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f48bf6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized GMRES_restarted Time: 79.91808819770813\n",
      "Our implementation residual with Ax-b (max_iterations = 500, restart = 10): 0.002920696046203375\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from scipy.sparse.linalg import gmres\n",
    "\n",
    "maxiter = 500\n",
    "restart = 10\n",
    "\n",
    "\n",
    "start_time = time()\n",
    "x, _,_ = precon_GMRES_restarted(prec , A, b, x0, k_max = maxiter, restart = None)\n",
    "residual_calculated2 = np.linalg.norm(A@x - b)\n",
    "end_time = time()\n",
    "print(\"Optimized GMRES_restarted Time:\", end_time - start_time)\n",
    "\n",
    "print(f\"Our implementation residual with Ax-b (max_iterations = {maxiter}, restart = {restart}): {residual_calculated2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e55991",
   "metadata": {},
   "source": [
    "IT TAKES CRAZY LONG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
